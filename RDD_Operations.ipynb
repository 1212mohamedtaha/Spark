{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required libraries then Create SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/20 11:03:15 WARN Utils: Your hostname, yourname.lab.local resolves to a loopback address: 127.0.1.1; using 192.168.236.129 instead (on interface ens33)\n",
      "21/10/20 11:03:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/10/20 11:03:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and display an RDD from the following list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [('JK', 22), ('V', 24), ('Jimin',24), ('RM', 25), ('J-Hope', 25), ('Suga', 26), ('Jin', 27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JK', 22),\n",
       " ('V', 24),\n",
       " ('Jimin', 24),\n",
       " ('RM', 25),\n",
       " ('J-Hope', 25),\n",
       " ('Suga', 26),\n",
       " ('Jin', 27)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distDataRDD = sc.parallelize(list1)\n",
    "distDataRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample1.txt file into RDD and displaying the first 4 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Utilitatis causa amicitia est quaesita.',\n",
       " 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. ',\n",
       " 'Collatio igitur ista te nihil iuvat. Honesta oratio, Socratica, Platonis etiam. Primum in nostrane potestate est, quid meminerimus? ',\n",
       " 'Duo Reges: constructio interrete. ']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distFile = sc.textFile('sample1.txt')\n",
    "distFile.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the total number of rows in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distFile.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to convert the data into lower case and splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['utilitatis', 'causa', 'amicitia', 'est', 'quaesita.'],\n",
       " ['lorem',\n",
       "  'ipsum',\n",
       "  'dolor',\n",
       "  'sit',\n",
       "  'amet,',\n",
       "  'consectetur',\n",
       "  'adipiscing',\n",
       "  'elit.'],\n",
       " ['collatio',\n",
       "  'igitur',\n",
       "  'ista',\n",
       "  'te',\n",
       "  'nihil',\n",
       "  'iuvat.',\n",
       "  'honesta',\n",
       "  'oratio,',\n",
       "  'socratica,',\n",
       "  'platonis',\n",
       "  'etiam.',\n",
       "  'primum',\n",
       "  'in',\n",
       "  'nostrane',\n",
       "  'potestate',\n",
       "  'est,',\n",
       "  'quid',\n",
       "  'meminerimus?'],\n",
       " ['duo', 'reges:', 'constructio', 'interrete.'],\n",
       " ['quid,',\n",
       "  'si',\n",
       "  'etiam',\n",
       "  'iucunda',\n",
       "  'memoria',\n",
       "  'est',\n",
       "  'praeteritorum',\n",
       "  'malorum?',\n",
       "  'si',\n",
       "  'quidem,',\n",
       "  'inquit,',\n",
       "  'tollerem,',\n",
       "  'sed',\n",
       "  'relinquo.',\n",
       "  'an',\n",
       "  'nisi',\n",
       "  'populari',\n",
       "  'fama?'],\n",
       " [],\n",
       " ['quamquam',\n",
       "  'id',\n",
       "  'quidem',\n",
       "  'licebit',\n",
       "  'iis',\n",
       "  'existimare,',\n",
       "  'qui',\n",
       "  'legerint.',\n",
       "  'summum',\n",
       "  'a',\n",
       "  'vobis',\n",
       "  'bonum',\n",
       "  'voluptas',\n",
       "  'dicitur.',\n",
       "  'at',\n",
       "  'hoc',\n",
       "  'in',\n",
       "  'eo',\n",
       "  'm.',\n",
       "  'refert',\n",
       "  'tamen,',\n",
       "  'quo',\n",
       "  'modo.',\n",
       "  'quid',\n",
       "  'sequatur,',\n",
       "  'quid',\n",
       "  'repugnet,',\n",
       "  'vident.',\n",
       "  'iam',\n",
       "  'id',\n",
       "  'ipsum',\n",
       "  'absurdum,',\n",
       "  'maximum',\n",
       "  'malum',\n",
       "  'neglegi.']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerdistFile = distFile.map(lambda x:x.lower().split())\n",
    "lowerdistFile.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the stopwords from the previous text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a','all','the','as','is','am','an','and',\n",
    "             'be','been','from','had','I','I’d','why','with','est']\n",
    "# Hint: you may need use flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utilitatis',\n",
       " 'causa',\n",
       " 'amicitia',\n",
       " 'quaesita.',\n",
       " 'lorem',\n",
       " 'ipsum',\n",
       " 'dolor',\n",
       " 'sit',\n",
       " 'amet,',\n",
       " 'consectetur',\n",
       " 'adipiscing',\n",
       " 'elit.',\n",
       " 'collatio',\n",
       " 'igitur',\n",
       " 'ista',\n",
       " 'te',\n",
       " 'nihil',\n",
       " 'iuvat.',\n",
       " 'honesta',\n",
       " 'oratio,',\n",
       " 'socratica,',\n",
       " 'platonis',\n",
       " 'etiam.',\n",
       " 'primum',\n",
       " 'in',\n",
       " 'nostrane',\n",
       " 'potestate',\n",
       " 'est,',\n",
       " 'quid',\n",
       " 'meminerimus?',\n",
       " 'duo',\n",
       " 'reges:',\n",
       " 'constructio',\n",
       " 'interrete.',\n",
       " 'quid,',\n",
       " 'si',\n",
       " 'etiam',\n",
       " 'iucunda',\n",
       " 'memoria',\n",
       " 'praeteritorum',\n",
       " 'malorum?',\n",
       " 'si',\n",
       " 'quidem,',\n",
       " 'inquit,',\n",
       " 'tollerem,',\n",
       " 'sed',\n",
       " 'relinquo.',\n",
       " 'nisi',\n",
       " 'populari',\n",
       " 'fama?',\n",
       " 'quamquam',\n",
       " 'id',\n",
       " 'quidem',\n",
       " 'licebit',\n",
       " 'iis',\n",
       " 'existimare,',\n",
       " 'qui',\n",
       " 'legerint.',\n",
       " 'summum',\n",
       " 'vobis',\n",
       " 'bonum',\n",
       " 'voluptas',\n",
       " 'dicitur.',\n",
       " 'at',\n",
       " 'hoc',\n",
       " 'in',\n",
       " 'eo',\n",
       " 'm.',\n",
       " 'refert',\n",
       " 'tamen,',\n",
       " 'quo',\n",
       " 'modo.',\n",
       " 'quid',\n",
       " 'sequatur,',\n",
       " 'quid',\n",
       " 'repugnet,',\n",
       " 'vident.',\n",
       " 'iam',\n",
       " 'id',\n",
       " 'ipsum',\n",
       " 'absurdum,',\n",
       " 'maximum',\n",
       " 'malum',\n",
       " 'neglegi.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterlowerdistFile = lowerdistFile.flatMap(lambda lst : [word for word in lst if word not in stopwords] )\n",
    "filterlowerdistFile.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the words starting with ‘c’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['causa', 'consectetur', 'collatio', 'constructio']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfilterlowerdistFile = filterlowerdistFile.filter(lambda x : x.startswith('c'))\n",
    "cfilterlowerdistFile.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the data by key and sum it (use the data from the following list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [('JK', 22), ('V', 24), ('Jimin',24), ('RM', 25)\n",
    "        , ('J-Hope', 25), ('Suga', 26), ('Jin', 27)\n",
    "       , ('J-Hope', 12), ('Suga', 25), ('Jin', 34)\n",
    "       , ('JK', 32), ('V', 44), ('Jimin',14), ('RM', 35)]\n",
    "# Hint: use reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Suga', 51),\n",
       " ('Jin', 61),\n",
       " ('JK', 54),\n",
       " ('V', 68),\n",
       " ('Jimin', 38),\n",
       " ('RM', 60),\n",
       " ('J-Hope', 37)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(list1)\n",
    "rdd.reduceByKey(lambda x,y : x + y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat some key value pairs RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([('a',2),('b',3)])\n",
    "rdd2 = sc.parallelize([('a',9),('b',7),('c',10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Join operation on the RDDs (rdd1,rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', (3, 7)), ('a', (2, 9))]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.join(rdd2).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
